/**
 * Unified Detector Service Entry Point
 *
 * Multi-chain detector that runs multiple blockchain detectors
 * in a single process based on partition configuration.
 *
 * Environment Variables:
 * - PARTITION_ID: Partition to run (default: asia-fast)
 * - PARTITION_CHAINS: Override chains (comma-separated)
 * - REDIS_URL: Redis connection URL
 * - LOG_LEVEL: Logging level (default: info)
 * - REGION_ID: Region for cross-region health reporting
 * - HEALTH_CHECK_PORT: HTTP health check port (default: 3001)
 *
 * @see ADR-003: Partitioned Chain Detectors
 */

// P3-1 FIX: Set max listeners before imports to prevent MaxListenersExceededWarning.
// Pino transports add process.on('exit') per logger, exceeding the default 10 limit.
process.setMaxListeners(25);

import { IncomingMessage, ServerResponse, Server } from 'http';
import { UnifiedChainDetector, UnifiedDetectorConfig } from './unified-detector';
import { parsePort } from '@arbitrage/core/partition';
import { getRedisStreamsClient, RedisStreamsClient } from '@arbitrage/core/redis';
import {
  createSimpleHealthServer,
  setupServiceShutdown,
  closeHealthServer,
  runServiceMain,
} from '@arbitrage/core/service-lifecycle';
import { createLogger } from '@arbitrage/core';
import { getPartition } from '@arbitrage/config';
import { DEFAULT_HEALTH_CHECK_PORT } from './constants';
import { OpportunityPublisher } from './publishers';

// =============================================================================
// Configuration
// =============================================================================

const logger = createLogger('unified-detector:main');

// Store server reference for graceful shutdown
let healthServer: Server | null = null;

// Store publisher and streams client references for lifecycle management
let opportunityPublisher: OpportunityPublisher | null = null;
let streamsClient: RedisStreamsClient | null = null;

// FIX M6: Track concurrent in-flight publishes to prevent burst overload
let inFlightPublishes = 0;
// P2-2 FIX: Made configurable via env var, aligned with partition runner (default: 100)
const MAX_CONCURRENT_PUBLISHES = parseInt(
  process.env.MAX_CONCURRENT_PUBLISHES ?? '100', 10
);

// FIX M11: Price update ingestion counter for monitoring
let priceUpdatesIngested = 0;

// FIX Inconsistency 6.2: Use parsePort for consistent port validation
const healthCheckPort = parsePort(process.env.HEALTH_CHECK_PORT, DEFAULT_HEALTH_CHECK_PORT, logger);

// Get region from partition config for consistent health response
const partitionConfig = process.env.PARTITION_ID ? getPartition(process.env.PARTITION_ID) : null;
// FIX L1: Use ?? for consistent nullish coalescing convention
const regionId = process.env.REGION_ID ?? partitionConfig?.region ?? 'asia-southeast1';

const config: UnifiedDetectorConfig = {
  partitionId: process.env.PARTITION_ID,
  chains: process.env.PARTITION_CHAINS?.split(',').map(c => c.trim()),
  instanceId: process.env.INSTANCE_ID ?? `unified-${process.env.HOSTNAME ?? 'local'}-${Date.now()}`,
  regionId,
  enableCrossRegionHealth: process.env.ENABLE_CROSS_REGION_HEALTH !== 'false',
  healthCheckPort
};

// =============================================================================
// Service Instance
// =============================================================================

const detector = new UnifiedChainDetector(config);

// =============================================================================
// HTTP Health Check Server
// FIX Inconsistency 6.1: Aligned response format with createPartitionHealthServer
// Uses shared createSimpleHealthServer() utility from @arbitrage/core
// =============================================================================

/** Health cache TTL in milliseconds (matches partition-service-utils) */
const HEALTH_CACHE_TTL_MS = 1000;

interface HealthCacheEntry {
  data: Awaited<ReturnType<typeof detector.getPartitionHealth>>;
  timestamp: number;
}

let healthCache: HealthCacheEntry | null = null;

function getHealthFromCache(): HealthCacheEntry['data'] | null {
  if (!healthCache) return null;
  if (Date.now() - healthCache.timestamp > HEALTH_CACHE_TTL_MS) {
    healthCache = null;
    return null;
  }
  return healthCache.data;
}

function setHealthCache(data: HealthCacheEntry['data']): void {
  healthCache = { data, timestamp: Date.now() };
}

/**
 * Create health server using shared createSimpleHealthServer utility.
 *
 * Endpoints provided:
 * - GET /health — Cached partition health (1s TTL) with chain/region data
 * - GET /ready — Readiness check with chain list
 * - GET /stats — Partition statistics
 * - GET /metrics — FIX H10: Prometheus-format metrics for scraping
 * - GET / — Service info with partition metadata (auto-generated by createSimpleHealthServer)
 */
function createHealthServer(port: number): Server {
  const serviceName = `unified-detector-${config.partitionId || 'default'}`;

  return createSimpleHealthServer({
    port,
    serviceName,
    logger,
    description: `${config.partitionId || 'unified'} Partition Detector`,
    healthCheck: async () => {
      // PERF-FIX: Use cached health data if available and fresh
      let health = getHealthFromCache();
      if (!health) {
        health = await detector.getPartitionHealth();
        setHealthCache(health);
      }

      // FIX H8: Check Redis connectivity via PING
      let redisHealthy = false;
      if (streamsClient) {
        redisHealthy = await streamsClient.ping();
        if (!redisHealthy) {
          logger.warn('Redis health check failed — publishing degraded');
        }
      }

      // FIX H7: Check stream lag and include in health response
      let streamLagCritical = false;
      const streamLagInfo: Record<string, { length: number; maxLen: number; lagRatio: number; critical: boolean }> = {};
      if (streamsClient && redisHealthy) {
        const criticalStreams = [
          RedisStreamsClient.STREAMS.PRICE_UPDATES,
          RedisStreamsClient.STREAMS.OPPORTUNITIES,
        ];
        for (const streamName of criticalStreams) {
          try {
            const lag = await streamsClient.checkStreamLag(streamName);
            streamLagInfo[streamName] = lag;
            if (lag.critical) {
              streamLagCritical = true;
              logger.warn('Stream lag critical in health check', {
                streamName, length: lag.length, maxLen: lag.maxLen,
                lagRatio: Math.round(lag.lagRatio * 100) / 100,
              });
            }
          } catch {
            // Stream check failed despite ping — don't fail health check
          }
        }
      }

      // Degrade status if Redis is down or stream lag is critical
      let effectiveStatus = health.status;
      if (!redisHealthy && effectiveStatus === 'healthy') {
        effectiveStatus = 'degraded';
      } else if (streamLagCritical && effectiveStatus === 'healthy') {
        effectiveStatus = 'degraded';
      }

      return {
        status: effectiveStatus,
        // Preserve explicit statusCode mapping (healthy/degraded=200, other=503)
        statusCode: effectiveStatus === 'healthy' || effectiveStatus === 'degraded' ? 200 : 503,
        partitionId: health.partitionId,
        chains: Array.from(health.chainHealth.keys()),
        healthyChains: detector.getHealthyChains(),
        uptime: health.uptimeSeconds,
        eventsProcessed: health.totalEventsProcessed,
        memoryMB: Math.round(health.memoryUsage / 1024 / 1024),
        region: regionId,
        redisHealthy,
        streamLag: streamLagInfo,
      };
    },
    readyCheck: () => detector.isRunning(),
    additionalRoutes: {
      // FIX H10: Prometheus metrics endpoint for monitoring/alerting
      '/metrics': async (_req: IncomingMessage, res: ServerResponse) => {
        try {
          const publisherStats = opportunityPublisher?.getStats();
          const stats = detector.getStats(publisherStats ?? undefined);
          const lines: string[] = [];

          // Event counters
          lines.push('# HELP detector_events_total Total events processed');
          lines.push('# TYPE detector_events_total counter');
          lines.push(`detector_events_total ${stats.totalEventsProcessed}`);

          // Opportunity counters
          lines.push('# HELP detector_opportunities_total Total opportunities detected');
          lines.push('# TYPE detector_opportunities_total counter');
          lines.push(`detector_opportunities_total ${stats.totalOpportunitiesFound}`);

          // Publisher stats
          if (publisherStats) {
            lines.push('# HELP detector_published_total Opportunities published');
            lines.push('# TYPE detector_published_total counter');
            lines.push(`detector_published_total ${publisherStats.published}`);
            lines.push('# HELP detector_publish_failed_total Publish failures');
            lines.push('# TYPE detector_publish_failed_total counter');
            lines.push(`detector_publish_failed_total ${publisherStats.failed}`);
            // FIX M10: Fast lane publish metrics
            lines.push('# HELP detector_fast_lane_published_total Fast lane publishes');
            lines.push('# TYPE detector_fast_lane_published_total counter');
            lines.push(`detector_fast_lane_published_total ${publisherStats.fastLanePublished}`);
            lines.push('# HELP detector_fast_lane_failed_total Fast lane failures');
            lines.push('# TYPE detector_fast_lane_failed_total counter');
            lines.push(`detector_fast_lane_failed_total ${publisherStats.fastLaneFailed}`);
          }

          // FIX M11: Price update ingestion rate
          lines.push('# HELP detector_price_updates_total Price updates ingested');
          lines.push('# TYPE detector_price_updates_total counter');
          lines.push(`detector_price_updates_total ${priceUpdatesIngested}`);

          // FIX M6: Concurrent publish tracking
          lines.push('# HELP detector_publish_in_flight Current in-flight publishes');
          lines.push('# TYPE detector_publish_in_flight gauge');
          lines.push(`detector_publish_in_flight ${inFlightPublishes}`);

          // Uptime
          lines.push('# HELP detector_uptime_seconds Service uptime');
          lines.push('# TYPE detector_uptime_seconds gauge');
          lines.push(`detector_uptime_seconds ${stats.uptimeSeconds}`);

          // Memory
          lines.push('# HELP detector_memory_mb Memory usage in MB');
          lines.push('# TYPE detector_memory_mb gauge');
          lines.push(`detector_memory_mb ${stats.memoryUsageMB}`);

          // Per-chain event counts
          lines.push('# HELP detector_chain_events_total Events per chain');
          lines.push('# TYPE detector_chain_events_total counter');
          for (const [chain, chainStats] of stats.chainStats) {
            lines.push(`detector_chain_events_total{chain="${chain}"} ${chainStats.eventsProcessed}`);
          }

          res.writeHead(200, { 'Content-Type': 'text/plain; version=0.0.4; charset=utf-8' });
          res.end(lines.join('\n') + '\n');
        } catch (error) {
          logger.error('Metrics endpoint error', { error: (error as Error).message });
          res.writeHead(500, { 'Content-Type': 'text/plain' });
          res.end('# Error generating metrics\n');
        }
      },
      '/stats': (_req: IncomingMessage, res: ServerResponse) => {
        try {
          // FIX C3: Pass publisher stats directly to getStats() to avoid post-hoc mutation
          const publisherStats = opportunityPublisher?.getStats();
          const stats = detector.getStats(publisherStats ?? undefined);
          res.writeHead(200, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({
            service: serviceName,
            partitionId: stats.partitionId,
            chains: stats.chains,
            totalEvents: stats.totalEventsProcessed,
            totalOpportunities: stats.totalOpportunitiesFound,
            uptimeSeconds: stats.uptimeSeconds,
            memoryMB: stats.memoryUsageMB,
            chainStats: Object.fromEntries(stats.chainStats),
            // FIX C3: Opportunity outcome tracking for detection quality monitoring
            opportunityOutcomes: stats.opportunityOutcomes,
          }));
        } catch (error) {
          logger.error('Stats endpoint error', { error: (error as Error).message });
          res.writeHead(500, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({
            service: serviceName,
            status: 'error',
          }));
        }
      },
    },
  });
}

// =============================================================================
// Event Handlers
// =============================================================================

// FIX M11: Track price update ingestion rate for monitoring
// Counter exposed via /metrics endpoint — no per-event logging (1000s/sec)
detector.on('priceUpdate', () => {
  priceUpdatesIngested++;
});

detector.on('opportunity', (opp) => {
  // P2-1 FIX: Reduced from INFO to DEBUG to cut log volume (~4k lines/sec)
  logger.debug('Arbitrage opportunity detected', {
    id: opp.id,
    type: opp.type,
    buyDex: opp.buyDex,
    sellDex: opp.sellDex,
    profit: opp.expectedProfit,
    percentage: opp.profitPercentage?.toFixed(2) + '%'  // profitPercentage is already a percentage value
  });

  // Publish opportunity to Redis Streams for Coordinator/Execution Engine
  // FIX P0: Fire-and-forget pattern with explicit error handling
  // FIX M6: Gate concurrent publishes to prevent burst overload on Redis
  if (opportunityPublisher) {
    if (inFlightPublishes >= MAX_CONCURRENT_PUBLISHES) {
      logger.warn('Concurrent publish limit reached, skipping', {
        opportunityId: opp.id,
        inFlight: inFlightPublishes,
        limit: MAX_CONCURRENT_PUBLISHES,
      });
      return;
    }
    inFlightPublishes++;
    opportunityPublisher.publish(opp)
      .catch((error) => {
        logger.error('Failed to publish opportunity (fire-and-forget)', {
          opportunityId: opp.id,
          error: (error as Error).message,
        });
      })
      .finally(() => {
        inFlightPublishes--;
      });
  }
});

detector.on('chainError', ({ chainId, error }) => {
  logger.error(`Chain error: ${chainId}`, { error: error.message });
});

detector.on('failoverEvent', (event) => {
  logger.warn('Failover event received', event);
});

// =============================================================================
// Graceful Shutdown (uses shared setupServiceShutdown from @arbitrage/core)
// =============================================================================

// =============================================================================
// Main Entry Point
// =============================================================================

async function main(): Promise<void> {
  logger.info('Starting Unified Detector Service', {
    partitionId: config.partitionId,
    chains: config.chains,
    region: regionId,
    nodeVersion: process.version,
    pid: process.pid
  });

  try {
    // Initialize Redis Streams client for opportunity publishing
    streamsClient = await getRedisStreamsClient();
    logger.info('Redis Streams client initialized for opportunity publishing');

    // Initialize opportunity publisher
    opportunityPublisher = new OpportunityPublisher({
      logger,
      streamsClient,
      partitionId: config.partitionId,
    });
    logger.info('OpportunityPublisher initialized');

    // Start health check server first
    healthServer = createHealthServer(config.healthCheckPort ?? DEFAULT_HEALTH_CHECK_PORT);

    // Start detector
    await detector.start();

    // Graceful shutdown with shared bootstrap utility
    setupServiceShutdown({
      logger,
      serviceName: 'Unified Detector',
      onShutdown: async () => {
        // BUG-FIX: Clear health cache to prevent stale data on restart scenarios
        healthCache = null;

        // Close health server first (with timeout via shared utility)
        await closeHealthServer(healthServer);

        // BUG-FIX: Remove event listeners from detector to prevent memory leaks
        // This is important if the process doesn't exit (e.g., in tests)
        detector.removeAllListeners();

        await detector.stop();

        // Log publisher stats before cleanup
        if (opportunityPublisher) {
          const stats = opportunityPublisher.getStats();
          logger.info('OpportunityPublisher stats at shutdown', {
            published: stats.published,
            failed: stats.failed,
          });
          opportunityPublisher = null;
        }

        // FIX P3: Clear streamsClient reference (singleton cleanup happens in detector.stop())
        // Note: getRedisStreamsClient() returns a singleton shared by both index.ts and
        // UnifiedChainDetector. The actual disconnect is handled by detector.stop() which
        // calls streamsClient.disconnect(). We just clear our reference here.
        // Setting to null prevents accidental use after shutdown.
        streamsClient = null;
      },
    });

    logger.info('Unified Detector Service started successfully', {
      partitionId: detector.getPartitionId(),
      chains: detector.getChains(),
      healthyChains: detector.getHealthyChains()
    });

  } catch (error) {
    logger.error('Failed to start Unified Detector Service', { error });

    // BUG-4.2-FIX: Await health server close before exiting
    await closeHealthServer(healthServer, 1000);

    process.exit(1);
  }
}

runServiceMain({ main, serviceName: 'Unified Detector Service', logger });

// =============================================================================
// Exports (re-export from exports.ts for backwards compatibility)
// =============================================================================

// NOTE: For library imports, use the package which points to exports.ts
// This file (index.ts) is the SERVICE entry point and should only be run directly.
// Re-exports are kept here for any code that directly imports from index.ts
export * from './exports';
